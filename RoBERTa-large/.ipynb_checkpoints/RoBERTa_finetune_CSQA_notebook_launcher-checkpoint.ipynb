{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4caa170a-73ef-47a8-996b-e3096fd73ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in /home/kyq5pg/.local/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: evaluate in /home/kyq5pg/.local/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: transformers[torch] in /home/kyq5pg/.local/lib/python3.10/site-packages (4.46.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/kyq5pg/.local/lib/python3.10/site-packages (from transformers[torch]) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.4.28)\n",
      "Requirement already satisfied: requests in /home/kyq5pg/.local/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/kyq5pg/.local/lib/python3.10/site-packages (from transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/kyq5pg/.local/lib/python3.10/site-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /home/kyq5pg/.local/lib/python3.10/site-packages (from transformers[torch]) (1.1.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.4.0a0+07cecf4168.nv24.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/kyq5pg/.local/lib/python3.10/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/kyq5pg/.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: xxhash in /home/kyq5pg/.local/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/kyq5pg/.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers[torch] datasets evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e23e6f-4356-4ab6-9280-12f9b334fc9f",
   "metadata": {},
   "source": [
    "## Define the model we fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37968702-71e3-42ef-99bf-ecfd0cb0c361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"FacebookAI/roberta-large\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a00482-9371-4138-bd3b-1ca7e294c62e",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24076283-8d82-49b6-954e-91676c1ee8e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"tau/commonsense_qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c1bcf4a-aa4f-42f9-8a34-6f152c3a6468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
       "        num_rows: 9741\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
       "        num_rows: 1221\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
       "        num_rows: 1140\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e24b4c5-3833-4f6f-893f-22ca57fbe8db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '075e483d21c29a511267ef62bedc0461',\n",
       " 'question': 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?',\n",
       " 'question_concept': 'punishing',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['ignore', 'enforce', 'authoritarian', 'yell at', 'avoid']},\n",
       " 'answerKey': 'A'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bf73e39-5cf9-4225-b2e9-b9f8a79e31fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1afa02df02c908a558b4036e80242fac',\n",
       " 'question': 'A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?',\n",
       " 'question_concept': 'revolving door',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['bank', 'library', 'department store', 'mall', 'new york']},\n",
       " 'answerKey': 'A'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"validation\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383fe843-7be9-4b5a-9246-734c0049a7f3",
   "metadata": {},
   "source": [
    "Notice, all the answerKey in test dataset are \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f515ad-7c15-40cb-a652-f0177da267c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '90b30172e645ff91f7171a048582eb8b',\n",
       " 'question': 'The townhouse was a hard sell for the realtor, it was right next to a high rise what?',\n",
       " 'question_concept': 'townhouse',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['suburban development',\n",
       "   'apartment building',\n",
       "   'bus stop',\n",
       "   'michigan',\n",
       "   'suburbs']},\n",
       " 'answerKey': ''}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462fdbc7-fd43-4f8c-a31d-8cfac1636791",
   "metadata": {},
   "source": [
    "#### The following function will show some examples picked randomly in the dataset to show what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e175bc07-88c3-4043-8054-170e719137c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92b50000-98fb-4c3e-b2b6-d212b629bea0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_concept</th>\n",
       "      <th>choices</th>\n",
       "      <th>answerKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>244b9eb979ac7b292fd437d717d0e2a6</td>\n",
       "      <td>What do people usually do when listening to music?</td>\n",
       "      <td>listening to music</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['dance', 'learning', 'enjoyment', 'shout', 'keep time']}</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4f23188516403427fbe4ee7d63b39fda</td>\n",
       "      <td>Where is a good place to buy a fishing rod?</td>\n",
       "      <td>rod</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['catch fish', 'fishing camp', 'dolphins', 'sporting goods store', 'engine']}</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46e2bed1736cdb103318245fe46e1462</td>\n",
       "      <td>What do you hold the handle of after going to Starbucks?</td>\n",
       "      <td>handle</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['gripping', 'briefcase', 'carry object', 'frying pan', 'coffee cup']}</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80c99f8ede4e2297cac15f099270997b</td>\n",
       "      <td>The hobbit was timid in front of the dragon, but what did he have to be to get the gold?</td>\n",
       "      <td>timid</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['mean', 'aggressive', 'bellicose', 'reckless', 'dauntless']}</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b101fb5d095d6c28caae45a7779338b0</td>\n",
       "      <td>How might someone relieve stress with friends?</td>\n",
       "      <td>stress</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['hang out at bar', 'running', 'drink alcohol', 'clean house', 'dream']}</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20cea584258e4de641f4331ccf815abd</td>\n",
       "      <td>All people need to move, otherwise what will atrophy?</td>\n",
       "      <td>all people</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['feelings', 'shrink', 'free will', 'muscles', 'parents']}</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>666fc2a353ed388ac74fe8e6fd0fba8c</td>\n",
       "      <td>What do you have when you are learning?</td>\n",
       "      <td>learning</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['attention', 'attention', 'study', 'thought', 'exposure']}</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9299a6bedf08ee7bbc3a79b8390a4018</td>\n",
       "      <td>If I was getting drunk and lost control of my inhibitions, what might happen to me?</td>\n",
       "      <td>getting drunk</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['pregnancy', 'forgetfulness', 'pass out', 'death', 'slurred speech']}</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6d4d55ea0479e63d6a0d37b19722b054</td>\n",
       "      <td>Where is the sky fake?</td>\n",
       "      <td>sky</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['shed', 'atmosphere', 'photo', 'outdoors', 'planetarium']}</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46e9f10bc0eb4a8e04f3eaa39783c243</td>\n",
       "      <td>If you have some excess corn, where would you put it?</td>\n",
       "      <td>corn</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['silo', 'storage building', 'restaurant', 'pennsylvania', 'supermarket']}</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7916cb52-303f-431b-a4df-548790282aa2",
   "metadata": {},
   "source": [
    "#### Define a function to check the ground truth of a specific question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17ba48f1-6c8f-411f-8f56-89872ce8490e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Question: {example['question']}\")\n",
    "    print(f\"  {example['choices']['label'][0]}:  {example['choices']['text'][0]}\")\n",
    "    print(f\"  {example['choices']['label'][1]}:  {example['choices']['text'][1]}\")\n",
    "    print(f\"  {example['choices']['label'][2]}:  {example['choices']['text'][2]}\")\n",
    "    print(f\"  {example['choices']['label'][3]}:  {example['choices']['text'][3]}\")\n",
    "    print(f\"  {example['choices']['label'][4]}:  {example['choices']['text'][4]}\")\n",
    "    print(f\"\\nGround truth: option {example['answerKey']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b585629b-f007-4bbb-bf14-0595013c2f82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\n",
      "  A:  ignore\n",
      "  B:  enforce\n",
      "  C:  authoritarian\n",
      "  D:  yell at\n",
      "  E:  avoid\n",
      "\n",
      "Ground truth: option A\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb53a760-5292-4dff-80ed-31e91de0c890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Johnny sat on a bench and relaxed after doing a lot of work on his hobby.  Where is he?\n",
      "  A:  state park\n",
      "  B:  bus depot\n",
      "  C:  garden\n",
      "  D:  gym\n",
      "  E:  rest area\n",
      "\n",
      "Ground truth: option C\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f2ec1c-4cfa-466c-802d-5c7bf51d1ec7",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b10b8f2e-74bd-4052-8bbc-4decac6dc6e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488c646a-2fb9-4da5-962e-c9454aaba8d3",
   "metadata": {},
   "source": [
    "Test the pretrained tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3a4effe-54b3-4d7d-b959-d1a685b57884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 31414, 6, 42, 16, 10, 3645, 328, 2, 2, 713, 16, 277, 3645, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello, this is a sentence!\", \"This is another sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ec919-af45-4d8b-8675-28a41de639d2",
   "metadata": {},
   "source": [
    "#### Define the function for batch encoding, which mainly connect the choices with its question sentance, then encode them.\n",
    "\n",
    "This function works with one or a batch of examples. In the case of a batch of examples, the tokenizer will return a list of lists of lists for each key, which is a list of all examples (here 6), then a list of all choices (5) and a list of input IDs (length varying here since we did not apply any padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dca227d-07a6-4f79-8bd0-516e61ead343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Extract the question stem\n",
    "    first_sentences = examples[\"question\"]  # List of question stems\n",
    "\n",
    "    # Extract all the answer texts (choices) from the 'choices' field\n",
    "    second_sentences = [choice_dict[\"text\"] for choice_dict in examples[\"choices\"]]  # List of lists\n",
    "\n",
    "    # Flatten the lists for tokenization\n",
    "    first_sentences = [stem for stem in first_sentences for _ in range(5)]  # Repeat each question 5 times\n",
    "    second_sentences = [choice for choices in second_sentences for choice in choices]  # Flatten choices\n",
    "\n",
    "    # Tokenize the question and choices\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "\n",
    "    # Group tokenized inputs by example (5 choices per question)\n",
    "    grouped_inputs = {\n",
    "        k: [v[i:i + 5] for i in range(0, len(v), 5)]  # Group every 5 entries\n",
    "        for k, v in tokenized_examples.items()\n",
    "    }\n",
    "\n",
    "    return grouped_inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148d575c-7b82-4889-b778-e4021c904e6f",
   "metadata": {},
   "source": [
    "Try to work on only 6 data examples to see if it can work corretly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec4933ce-8dbd-4d1c-8267-6d1f55c9111d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 5 [29, 30, 30, 31, 29]\n"
     ]
    }
   ],
   "source": [
    "examples = dataset[\"train\"][:6]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d062722-2515-40e7-adbc-a61cdb380dbe",
   "metadata": {},
   "source": [
    "To make sure we didn't do anything wrong when grouping all possibilites and unflattening. We have a look at the decoded inputs for a given example. We will decode the encoded examples to see the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa62c118-6cca-4ba4-a18d-eca3dc1f25a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>Google Maps and other highway and street GPS services have replaced what?</s></s>united states</s>',\n",
       " '<s>Google Maps and other highway and street GPS services have replaced what?</s></s>mexico</s>',\n",
       " '<s>Google Maps and other highway and street GPS services have replaced what?</s></s>countryside</s>',\n",
       " '<s>Google Maps and other highway and street GPS services have replaced what?</s></s>atlas</s>',\n",
       " '<s>Google Maps and other highway and street GPS services have replaced what?</s></s>oceans</s>']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 3\n",
    "[tokenizer.decode(features[\"input_ids\"][idx][i]) for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24629243-23b7-4001-89ae-99595bf9678f",
   "metadata": {},
   "source": [
    "Then, we compare it with the ground truth from the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1245a4f7-665a-4557-bb17-0ebe31a864e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Google Maps and other highway and street GPS services have replaced what?\n",
      "  A:  united states\n",
      "  B:  mexico\n",
      "  C:  countryside\n",
      "  D:  atlas\n",
      "  E:  oceans\n",
      "\n",
      "Ground truth: option D\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea939e0c-9134-43f3-ac9d-07ec6e213981",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### They look correct. Then we can go to encode the entire dataset, including our training, validation and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "658d31cb-9344-45c4-8ff7-0c3732e1b9ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dd5c40-d414-4669-82c3-e15eba5c9ed6",
   "metadata": {},
   "source": [
    "### Important! some postprocessing to our encoded_dataset\n",
    "Before using the Trainer API or defining the dataloaders for training loops,\n",
    "we have to apply a bit of postprocessing to our encoded_dataset, to take care of some things that the Trainer did for us automatically. Specifically, we need to:\n",
    "1. Remove the columns corresponding to values the model does not expect (like the question, choices and question_concept columns).\n",
    "2. Rename the column 'answerKey' to 'labels' (because the model expects the argument to be named 'labels').\n",
    "3. Set the format of the datasets so they return PyTorch tensors instead of lists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c414c909-4050-4878-bfd1-db2f67d4ccda",
   "metadata": {
    "tags": []
   },
   "source": [
    "Rename the column 'answerKey' to 'labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f28b4b2-8a25-4385-944b-51c6fc70e0a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_dataset = encoded_dataset.rename_column(\"answerKey\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d7d57d9-f29b-4d1e-a718-5430cc9088be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'question_concept', 'choices', 'labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 9741\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c0931-4a23-4d7c-b028-64a72e0341ad",
   "metadata": {},
   "source": [
    "Set the format of the datasets so they return PyTorch tensors instead of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3a1b19e-1f32-4e54-959b-7ea991b217f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da14cac0-9ae0-4713-995e-2f321ccbb48d",
   "metadata": {},
   "source": [
    "Remove the columns corresponding to values the model does not expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "910a4e75-53fa-419c-88a0-8e5c6baa37cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'question',\n",
       " 'question_concept',\n",
       " 'choices',\n",
       " 'labels',\n",
       " 'input_ids',\n",
       " 'attention_mask']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9b6f1d2-1c0c-49e3-8ab0-5836e42ada69",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = encoded_dataset.remove_columns([\n",
    "    'id',\n",
    "     'question',\n",
    "     'question_concept',\n",
    "     'choices',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11f8cc64-274d-422e-b74e-0394ea880e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels', 'input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c9b229-b7a6-46d6-8255-5289ad89a572",
   "metadata": {},
   "source": [
    "### Define DataCollatorForMultipleChoice for batch padding\n",
    "We need to add batch padding to the tokenized data using data collator.\n",
    "\n",
    "Hugging Face transformers doesn't have a data collator for multiple choice, so we need to adapt the DataCollatorWithPadding to create a batch of examples. It's more efficient to dynamically pad the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length.\n",
    "\n",
    "DataCollatorForMultipleChoice flattens all the model inputs, applies padding, and then unflattens the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01beca29-b29c-4c40-a820-27fa75947acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        \n",
    "        labels = [feature.pop(\"labels\") for feature in features]\n",
    "\n",
    "        # Map answerKey (e.g., \"A\", \"B\", ...) to numerical indices\n",
    "        labels = torch.tensor(\n",
    "            [[\"A\", \"B\", \"C\", \"D\", \"E\"].index(label) for label in labels],\n",
    "            dtype=torch.int64\n",
    "        )\n",
    "\n",
    "        # Determine batch size and number of choices\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "\n",
    "        # Flatten features for tokenization\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)]\n",
    "            for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])  # Flatten the list of lists\n",
    "\n",
    "        # Apply padding to the flattened features\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Un-flatten to restore batch structure (batch_size, num_choices, sequence_length)\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "\n",
    "        # Add back the labels as a tensor\n",
    "        # batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdbd56a-b3d5-440a-911c-5bf6255d35d0",
   "metadata": {},
   "source": [
    "When called on a list of examples, it will flatten all the inputs/attentions masks etc. in big lists that it will pass to the tokenizer.pad method. This will return a dictionary with big tensors (of shape (batch_size * 5) x seq_length) that we then unflatten.\n",
    "\n",
    "We can check this data collator works on a list of features, we just have to make sure to remove all features that are not inputs accepted by our model (something the Trainer will do automatically for us after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c081f6f9-a022-4019-989b-d5f72aa29bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "# pick out only 10 data examples\n",
    "features = [{k: v for k, v in encoded_dataset[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "collator = DataCollatorForMultipleChoice(tokenizer)\n",
    "batch = collator(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8537008c-da57-46e5-9118-8b28f18d478c",
   "metadata": {},
   "source": [
    "Check the data collator works on a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e2821e6-abc1-476c-9917-d7bc71865f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>The forgotten leftovers had gotten quite old, he found it covered in mold in the back of his what?</s></s>carpet</s><pad><pad>',\n",
       " '<s>The forgotten leftovers had gotten quite old, he found it covered in mold in the back of his what?</s></s>refrigerator</s><pad><pad>',\n",
       " '<s>The forgotten leftovers had gotten quite old, he found it covered in mold in the back of his what?</s></s>breadbox</s><pad><pad><pad>',\n",
       " '<s>The forgotten leftovers had gotten quite old, he found it covered in mold in the back of his what?</s></s>fridge</s><pad><pad><pad>',\n",
       " '<s>The forgotten leftovers had gotten quite old, he found it covered in mold in the back of his what?</s></s>coach</s><pad><pad><pad>']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The example 7, and its 5 combinations\n",
    "[tokenizer.decode(batch[\"input_ids\"][7][i].tolist()) for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0668f8d7-1238-47ef-a666-8e1e0ee40457",
   "metadata": {},
   "source": [
    "Compare it with the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db98c658-7261-488c-8ee7-fadaae0ea718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: The forgotten leftovers had gotten quite old, he found it covered in mold in the back of his what?\n",
      "  A:  carpet\n",
      "  B:  refrigerator\n",
      "  C:  breadbox\n",
      "  D:  fridge\n",
      "  E:  coach\n",
      "\n",
      "Ground truth: option B\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faea4b1f-e6b3-43fa-ad0c-e3895e2a433b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define the dataloaders\n",
    "We need to define the dataloaders that we will use to iterate over batches. Before that, we need to get a instance of the DataCollatorForMultipleChoice we defined earlier, which will be used to defined the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e541efd2-2bf5-47d6-8dff-7e0c7f2fca4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0678d2e-e299-4f2f-9721-fcc2ef3e7c06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    encoded_dataset[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    encoded_dataset[\"validation\"], batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca08af-f0c9-485f-80a8-14a64c751329",
   "metadata": {},
   "source": [
    "To quickly check there is no mistake in the data processing, we can inspect a batch like this.\n",
    "\n",
    "The shapes will probably be slightly different after each time running the code, since we set shuffle=True for the training dataloader and we are padding to the maximum length inside the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94e59191-9320-478f-bd4a-c4f278b51149",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 5, 29]),\n",
       " 'attention_mask': torch.Size([8, 5, 29]),\n",
       " 'labels': torch.Size([8])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447c9f25-6c20-4da1-8db0-b0f8a0066971",
   "metadata": {},
   "source": [
    "# Fine-tune the RoBERTa-Large model - with self-defined training loops\n",
    "To utilize the multiple GPU, we need to rather putting them into a train.py script and run the command `accelerate config` and `accelerate launch train.py`, or using the `notebook_launcher` if we are using multiple GPU inside the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4af4cf79-e675-4f86-81e8-5b00ab78b8ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_function():\n",
    "    # load the model\n",
    "    from transformers import AutoModelForMultipleChoice\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)\n",
    "\n",
    "    # initialize optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-05)\n",
    "\n",
    "    # initialize accelerator\n",
    "    from accelerate import Accelerator\n",
    "    accelerator = Accelerator()\n",
    "\n",
    "    # prepare dataloaders, model, and optimizer with the accelerator\n",
    "    train_dl, eval_dl, model, optimizer = accelerator.prepare(\n",
    "        train_dataloader, eval_dataloader, model, optimizer\n",
    "    )\n",
    "\n",
    "    # learning rate scheduler\n",
    "    from transformers import get_scheduler\n",
    "    num_epochs = 3\n",
    "    # important! we should use train_dl here rather than train_dataloader, thus ensuring the compatibility with distributed training.\n",
    "    # because, train_dl is split across the number of devices (e.g., GPUs, TPUs) used for distributed training.\n",
    "    num_training_steps = num_epochs * len(train_dl)\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_training_steps,\n",
    "    )\n",
    "\n",
    "    # initialize the progress bar\n",
    "    from tqdm.auto import tqdm\n",
    "    # to avoid showing progress bar for each GPU, we only show it for the main process\n",
    "    progress_bar = tqdm(range(num_training_steps), disable=not accelerator.is_main_process)\n",
    "\n",
    "    # load evaluation metric\n",
    "    import evaluate\n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    f1_metric = evaluate.load(\"f1\")\n",
    "    precision_metric = evaluate.load(\"precision\")\n",
    "    recall_metric = evaluate.load(\"recall\")\n",
    "    \n",
    "    # initialize variables to track best accuracy and save best model\n",
    "    best_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "\n",
    "    # ======================================== training loop ========================================\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        # training for this epoch\n",
    "        for batch in train_dl:\n",
    "            # Forward pass\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        # evaluation loop for this epoch\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "\n",
    "        for batch in eval_dl:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            # gather predictions and labels across all devices\n",
    "            all_predictions.append(accelerator.gather(predictions))\n",
    "            all_labels.append(accelerator.gather(batch[\"labels\"]))\n",
    "\n",
    "        # concatenate all predictions and labels\n",
    "        all_predictions = torch.cat(all_predictions)\n",
    "        all_labels = torch.cat(all_labels)\n",
    "\n",
    "        # compute metric\n",
    "        accuracy = accuracy_metric.compute(predictions=all_predictions, references=all_labels)\n",
    "        f1 = f1_metric.compute(predictions=all_predictions, references=all_labels, average=\"weighted\")\n",
    "        precision = precision_metric.compute(predictions=all_predictions, references=all_labels, average=\"weighted\")\n",
    "        recall = recall_metric.compute(predictions=all_predictions, references=all_labels, average=\"weighted\")\n",
    "\n",
    "        # combine all metrics into a single dictionary\n",
    "        eval_metrics = {\n",
    "            \"accuracy\": accuracy[\"accuracy\"],\n",
    "            \"f1\": f1[\"f1\"],\n",
    "            \"precision\": precision[\"precision\"],\n",
    "            \"recall\": recall[\"recall\"],\n",
    "        }\n",
    "\n",
    "        # use accelerator.print to print only on the main process\n",
    "        accelerator.print(\"Evaluation results:\", eval_metrics)\n",
    "        \n",
    "        # check if this is the best model so far\n",
    "        if accuracy[\"accuracy\"] > best_accuracy:\n",
    "            best_accuracy = accuracy[\"accuracy\"]\n",
    "            # save model state\n",
    "            best_model_state = accelerator.unwrap_model(model).state_dict()\n",
    "\n",
    "        # set the model back to training mode for next epoch\n",
    "        model.train()\n",
    "    # ====================================================================================================\n",
    "        \n",
    "    # Load the best model at the end of training\n",
    "    if best_model_state is not None:\n",
    "        accelerator.unwrap_model(model).load_state_dict(best_model_state)\n",
    "\n",
    "    # Print the best accuracy\n",
    "    accelerator.print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbdd5115-45c9-4bc7-a898-52511c7268d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f847f2b40c604b7494366dc3bfd2d737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1827 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'accuracy': 0.20535714285714285, 'f1': 0.2055868750547292, 'precision': 0.20589373480688242, 'recall': 0.20535714285714285}\n",
      "Evaluation results: {'accuracy': 0.19724025974025974, 'f1': 0.19687786081756548, 'precision': 0.19689130489402723, 'recall': 0.19724025974025974}\n",
      "Evaluation results: {'accuracy': 0.21753246753246752, 'f1': 0.21801789374033176, 'precision': 0.2191892324118451, 'recall': 0.21753246753246752}\n",
      "Best Accuracy: 0.21753246753246752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1129 20:48:48.297000 139665202651776 torch/distributed/elastic/multiprocessing/api.py:727] Closing process 890287 via signal SIGTERM\n"
     ]
    }
   ],
   "source": [
    "from accelerate import notebook_launcher\n",
    "\n",
    "notebook_launcher(training_function, num_processes=2) # num_processes is the number of GPUs we would like to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c05c3a-3bc5-403d-a956-18178c2c806e",
   "metadata": {},
   "source": [
    "### Notice:\n",
    "This is not the optimized accuracy ressult. We have done grid search in another notebook, which reaches a highest accuracy of 0.764. Please, refer to the file `RoBERTa_finetune_CSQA_optimized.ipynb` for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec67197-1e4f-4df6-9ee6-2a27b08772aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0840c67-a6c3-4b7b-a3f4-cc72ab8160a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7c51d0-ddeb-4561-87b9-6ecb70a0a414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e7ef77-a4e2-4e7a-be37-e9764cf90825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbfaffb-8be4-4f90-bc22-8133c9554a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.4.0",
   "language": "python",
   "name": "pytorch-2.4.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
