{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1f61371-ee31-4520-a5d0-af9a70444ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in /home/kyq5pg/.local/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: evaluate in /home/kyq5pg/.local/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: transformers[torch] in /home/kyq5pg/.local/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/kyq5pg/.local/lib/python3.10/site-packages (from transformers[torch]) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.4.28)\n",
      "Requirement already satisfied: requests in /home/kyq5pg/.local/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/kyq5pg/.local/lib/python3.10/site-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/kyq5pg/.local/lib/python3.10/site-packages (from transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.4.0a0+07cecf4168.nv24.5)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /home/kyq5pg/.local/lib/python3.10/site-packages (from transformers[torch]) (1.1.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/kyq5pg/.local/lib/python3.10/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/kyq5pg/.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: xxhash in /home/kyq5pg/.local/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/kyq5pg/.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers[torch] datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466999c8-6bfd-4997-8db1-65c6b8d9cd90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.46.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e23e6f-4356-4ab6-9280-12f9b334fc9f",
   "metadata": {},
   "source": [
    "## Define the model we fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37968702-71e3-42ef-99bf-ecfd0cb0c361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"bert-base-uncased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a00482-9371-4138-bd3b-1ca7e294c62e",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24076283-8d82-49b6-954e-91676c1ee8e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"tau/commonsense_qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c1bcf4a-aa4f-42f9-8a34-6f152c3a6468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
       "        num_rows: 9741\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
       "        num_rows: 1221\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
       "        num_rows: 1140\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e24b4c5-3833-4f6f-893f-22ca57fbe8db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '075e483d21c29a511267ef62bedc0461',\n",
       " 'question': 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?',\n",
       " 'question_concept': 'punishing',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['ignore', 'enforce', 'authoritarian', 'yell at', 'avoid']},\n",
       " 'answerKey': 'A'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bf73e39-5cf9-4225-b2e9-b9f8a79e31fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1afa02df02c908a558b4036e80242fac',\n",
       " 'question': 'A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?',\n",
       " 'question_concept': 'revolving door',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['bank', 'library', 'department store', 'mall', 'new york']},\n",
       " 'answerKey': 'A'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"validation\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383fe843-7be9-4b5a-9246-734c0049a7f3",
   "metadata": {},
   "source": [
    "Notice, all the answerKey in test dataset are \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3f515ad-7c15-40cb-a652-f0177da267c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '90b30172e645ff91f7171a048582eb8b',\n",
       " 'question': 'The townhouse was a hard sell for the realtor, it was right next to a high rise what?',\n",
       " 'question_concept': 'townhouse',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['suburban development',\n",
       "   'apartment building',\n",
       "   'bus stop',\n",
       "   'michigan',\n",
       "   'suburbs']},\n",
       " 'answerKey': ''}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462fdbc7-fd43-4f8c-a31d-8cfac1636791",
   "metadata": {},
   "source": [
    "#### The following function will show some examples picked randomly in the dataset to show what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e175bc07-88c3-4043-8054-170e719137c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92b50000-98fb-4c3e-b2b6-d212b629bea0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_concept</th>\n",
       "      <th>choices</th>\n",
       "      <th>answerKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4af505b05f7ebf0d26a8e8005b09d1a5</td>\n",
       "      <td>The person was having a difficult time understanding the computer program, they were beginning to what?</td>\n",
       "      <td>program</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['stare at computer screen', 'compile', 'get frustrated', 'write code', 'think logically']}</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f90b3ff30ef328a6e69e5f7100e8c26</td>\n",
       "      <td>John heard a language that he could not understand. He thought that the door was shut, but he eventually realized that there was no door, and that the light source that was blinding his eyes was very familiar.  He was on his back looking at what?</td>\n",
       "      <td>light source</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['sky', 'lamp', 'hallway', 'dard', 'closed room']}</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>433c513e36799605b6d80fb3aebc28ea</td>\n",
       "      <td>What does a person sometimes do after they finish secondary education?</td>\n",
       "      <td>person</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['enter college', 'feel lonely', 'cross street', 'pass exams', 'graduate from high school']}</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a9424d6cdb772a61e8d2a61d987faad5</td>\n",
       "      <td>In what place could you find air that has been breathed by many people recently?</td>\n",
       "      <td>air</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['charming', 'space shuttle', 'house', 'train station', 'surface of earth']}</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fbcf10712db557876083b6256c55948b</td>\n",
       "      <td>What will a person have when very happy?</td>\n",
       "      <td>person</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['own car', 'be rich', 'catch cold', 'believe in god', 'experience joy']}</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f4cbde41c795a3f32f0e1ebb243c1b1e</td>\n",
       "      <td>Cats are laying by the refrigerator why do they do that?</td>\n",
       "      <td>cats</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['lie down', 'like heat', 'eating fish', 'drink water', 'come to dinner']}</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>555fba06a60a28eeaf3f7e97b46f30db</td>\n",
       "      <td>What are people in a library likely doing?</td>\n",
       "      <td>people</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['talk to each other', 'board ships', 'study books', 'suffer hunger', 'playing games']}</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5cc458ffab4d95c112ccef14ae75504b</td>\n",
       "      <td>Steve was surprised to find an underground map while he was shopping and carrots and paperback books.  Where might he have found it?</td>\n",
       "      <td>underground map</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['subway station', 'library', 'super market', 'county engineer's office', 'a friend']}</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9cdc71eb5fc6b8b76b4768564ea3fe1e</td>\n",
       "      <td>He was eating too much and the doctors warned him, what was his condition?</td>\n",
       "      <td>eating too much</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['gain weight', 'obesity', 'getting fit', 'getting sick', 'gas']}</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ddd867663ebf4ed94d6844b6d1699c95</td>\n",
       "      <td>The archaeologist was seeing artifacts that he knew were fake, how did he feel?</td>\n",
       "      <td>seeing artifacts</td>\n",
       "      <td>{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['pleasure', 'awe inspiring', 'angry', 'thinking', 'painful memories']}</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7916cb52-303f-431b-a4df-548790282aa2",
   "metadata": {},
   "source": [
    "#### Define a function to check the ground truth of a specific question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17ba48f1-6c8f-411f-8f56-89872ce8490e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_one(example):\n",
    "    print(f\"Question: {example['question']}\")\n",
    "    print(f\"  {example['choices']['label'][0]}:  {example['choices']['text'][0]}\")\n",
    "    print(f\"  {example['choices']['label'][1]}:  {example['choices']['text'][1]}\")\n",
    "    print(f\"  {example['choices']['label'][2]}:  {example['choices']['text'][2]}\")\n",
    "    print(f\"  {example['choices']['label'][3]}:  {example['choices']['text'][3]}\")\n",
    "    print(f\"  {example['choices']['label'][4]}:  {example['choices']['text'][4]}\")\n",
    "    print(f\"\\nGround truth: option {example['answerKey']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b585629b-f007-4bbb-bf14-0595013c2f82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\n",
      "  A:  ignore\n",
      "  B:  enforce\n",
      "  C:  authoritarian\n",
      "  D:  yell at\n",
      "  E:  avoid\n",
      "\n",
      "Ground truth: option A\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb53a760-5292-4dff-80ed-31e91de0c890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Johnny sat on a bench and relaxed after doing a lot of work on his hobby.  Where is he?\n",
      "  A:  state park\n",
      "  B:  bus depot\n",
      "  C:  garden\n",
      "  D:  gym\n",
      "  E:  rest area\n",
      "\n",
      "Ground truth: option C\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f2ec1c-4cfa-466c-802d-5c7bf51d1ec7",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b10b8f2e-74bd-4052-8bbc-4decac6dc6e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488c646a-2fb9-4da5-962e-c9454aaba8d3",
   "metadata": {},
   "source": [
    "Test the pretrained tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3a4effe-54b3-4d7d-b959-d1a685b57884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 1010, 2023, 2003, 1037, 6251, 999, 102, 2023, 2003, 2178, 6251, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello, this is a sentence!\", \"This is another sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ec919-af45-4d8b-8675-28a41de639d2",
   "metadata": {},
   "source": [
    "#### Define the function for batch encoding, which mainly connect the choices with its question sentance, then encode them.\n",
    "\n",
    "This function works with one or a batch of examples. In the case of a batch of examples, the tokenizer will return a list of lists of lists for each key, which is a list of all examples (here 6), then a list of all choices (5) and a list of input IDs (length varying here since we did not apply any padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dca227d-07a6-4f79-8bd0-516e61ead343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Extract the question stem\n",
    "    first_sentences = examples[\"question\"]  # List of question stems\n",
    "\n",
    "    # Extract all the answer texts (choices) from the 'choices' field\n",
    "    second_sentences = [choice_dict[\"text\"] for choice_dict in examples[\"choices\"]]  # List of lists\n",
    "\n",
    "    # Flatten the lists for tokenization\n",
    "    first_sentences = [stem for stem in first_sentences for _ in range(5)]  # Repeat each question 5 times\n",
    "    second_sentences = [choice for choices in second_sentences for choice in choices]  # Flatten choices\n",
    "\n",
    "    # Tokenize the question and choices\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "\n",
    "    # Group tokenized inputs by example (5 choices per question)\n",
    "    grouped_inputs = {\n",
    "        k: [v[i:i + 5] for i in range(0, len(v), 5)]  # Group every 5 entries\n",
    "        for k, v in tokenized_examples.items()\n",
    "    }\n",
    "\n",
    "    return grouped_inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148d575c-7b82-4889-b778-e4021c904e6f",
   "metadata": {},
   "source": [
    "Try to work on only 6 data examples to see if it can work corretly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec4933ce-8dbd-4d1c-8267-6d1f55c9111d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 5 [29, 29, 29, 30, 29]\n"
     ]
    }
   ],
   "source": [
    "examples = dataset[\"train\"][:6]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d062722-2515-40e7-adbc-a61cdb380dbe",
   "metadata": {},
   "source": [
    "To make sure we didn't do anything wrong when grouping all possibilites and unflattening. We have a look at the decoded inputs for a given example. We will decode the encoded examples to see the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa62c118-6cca-4ba4-a18d-eca3dc1f25a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] google maps and other highway and street gps services have replaced what? [SEP] united states [SEP]',\n",
       " '[CLS] google maps and other highway and street gps services have replaced what? [SEP] mexico [SEP]',\n",
       " '[CLS] google maps and other highway and street gps services have replaced what? [SEP] countryside [SEP]',\n",
       " '[CLS] google maps and other highway and street gps services have replaced what? [SEP] atlas [SEP]',\n",
       " '[CLS] google maps and other highway and street gps services have replaced what? [SEP] oceans [SEP]']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 3\n",
    "[tokenizer.decode(features[\"input_ids\"][idx][i]) for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24629243-23b7-4001-89ae-99595bf9678f",
   "metadata": {},
   "source": [
    "Then, we compare it with the ground truth from the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1245a4f7-665a-4557-bb17-0ebe31a864e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Google Maps and other highway and street GPS services have replaced what?\n",
      "  A:  united states\n",
      "  B:  mexico\n",
      "  C:  countryside\n",
      "  D:  atlas\n",
      "  E:  oceans\n",
      "\n",
      "Ground truth: option D\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea939e0c-9134-43f3-ac9d-07ec6e213981",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### They look correct. Then we can go to encode the entire dataset, including our training, validation and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "658d31cb-9344-45c4-8ff7-0c3732e1b9ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dd5c40-d414-4669-82c3-e15eba5c9ed6",
   "metadata": {},
   "source": [
    "### Important! some postprocessing to our encoded_dataset\n",
    "Before using the Trainer API or defining the dataloaders for training loops,\n",
    "we have to apply a bit of postprocessing to our encoded_dataset, to take care of some things that the Trainer did for us automatically. Specifically, we need to:\n",
    "1. Remove the columns corresponding to values the model does not expect (like the question, choices and question_concept columns).\n",
    "2. Rename the column 'answerKey' to 'labels' (because the model expects the argument to be named 'labels').\n",
    "3. Set the format of the datasets so they return PyTorch tensors instead of lists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c414c909-4050-4878-bfd1-db2f67d4ccda",
   "metadata": {
    "tags": []
   },
   "source": [
    "Rename the column 'answerKey' to 'labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f28b4b2-8a25-4385-944b-51c6fc70e0a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_dataset = encoded_dataset.rename_column(\"answerKey\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d7d57d9-f29b-4d1e-a718-5430cc9088be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'question_concept', 'choices', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 9741\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c0931-4a23-4d7c-b028-64a72e0341ad",
   "metadata": {},
   "source": [
    "Set the format of the datasets so they return PyTorch tensors instead of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3a1b19e-1f32-4e54-959b-7ea991b217f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da14cac0-9ae0-4713-995e-2f321ccbb48d",
   "metadata": {},
   "source": [
    "Remove the columns corresponding to values the model does not expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "910a4e75-53fa-419c-88a0-8e5c6baa37cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'question',\n",
       " 'question_concept',\n",
       " 'choices',\n",
       " 'labels',\n",
       " 'input_ids',\n",
       " 'token_type_ids',\n",
       " 'attention_mask']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9b6f1d2-1c0c-49e3-8ab0-5836e42ada69",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = encoded_dataset.remove_columns([\n",
    "    'id',\n",
    "     'question',\n",
    "     'question_concept',\n",
    "     'choices',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11f8cc64-274d-422e-b74e-0394ea880e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c9b229-b7a6-46d6-8255-5289ad89a572",
   "metadata": {},
   "source": [
    "### Define DataCollatorForMultipleChoice for batch padding\n",
    "We need to add batch padding to the tokenized data using data collator.\n",
    "\n",
    "Hugging Face transformers doesn't have a data collator for multiple choice, so we need to adapt the DataCollatorWithPadding to create a batch of examples. It's more efficient to dynamically pad the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length.\n",
    "\n",
    "DataCollatorForMultipleChoice flattens all the model inputs, applies padding, and then unflattens the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01beca29-b29c-4c40-a820-27fa75947acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        \n",
    "        labels = [feature.pop(\"labels\") for feature in features]\n",
    "\n",
    "        # Map answerKey (e.g., \"A\", \"B\", ...) to numerical indices\n",
    "        labels = torch.tensor(\n",
    "            [[\"A\", \"B\", \"C\", \"D\", \"E\"].index(label) for label in labels],\n",
    "            dtype=torch.int64\n",
    "        )\n",
    "\n",
    "        # Determine batch size and number of choices\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "\n",
    "        # Flatten features for tokenization\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)]\n",
    "            for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])  # Flatten the list of lists\n",
    "\n",
    "        # Apply padding to the flattened features\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Un-flatten to restore batch structure (batch_size, num_choices, sequence_length)\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "\n",
    "        # Add back the labels as a tensor\n",
    "        # batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdbd56a-b3d5-440a-911c-5bf6255d35d0",
   "metadata": {},
   "source": [
    "When called on a list of examples, it will flatten all the inputs/attentions masks etc. in big lists that it will pass to the tokenizer.pad method. This will return a dictionary with big tensors (of shape (batch_size * 5) x seq_length) that we then unflatten.\n",
    "\n",
    "We can check this data collator works on a list of features, we just have to make sure to remove all features that are not inputs accepted by our model (something the Trainer will do automatically for us after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c081f6f9-a022-4019-989b-d5f72aa29bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "# pick out only 10 data examples\n",
    "features = [{k: v for k, v in encoded_dataset[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "collator = DataCollatorForMultipleChoice(tokenizer)\n",
    "batch = collator(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8537008c-da57-46e5-9118-8b28f18d478c",
   "metadata": {},
   "source": [
    "Check the data collator works on a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e2821e6-abc1-476c-9917-d7bc71865f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] the forgotten leftovers had gotten quite old, he found it covered in mold in the back of his what? [SEP] carpet [SEP] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] the forgotten leftovers had gotten quite old, he found it covered in mold in the back of his what? [SEP] refrigerator [SEP] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] the forgotten leftovers had gotten quite old, he found it covered in mold in the back of his what? [SEP] breadbox [SEP] [PAD] [PAD] [PAD]',\n",
       " '[CLS] the forgotten leftovers had gotten quite old, he found it covered in mold in the back of his what? [SEP] fridge [SEP] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] the forgotten leftovers had gotten quite old, he found it covered in mold in the back of his what? [SEP] coach [SEP] [PAD] [PAD] [PAD] [PAD]']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The example 7, and its 5 combinations\n",
    "[tokenizer.decode(batch[\"input_ids\"][7][i].tolist()) for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0668f8d7-1238-47ef-a666-8e1e0ee40457",
   "metadata": {},
   "source": [
    "Compare it with the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db98c658-7261-488c-8ee7-fadaae0ea718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: The forgotten leftovers had gotten quite old, he found it covered in mold in the back of his what?\n",
      "  A:  carpet\n",
      "  B:  refrigerator\n",
      "  C:  breadbox\n",
      "  D:  fridge\n",
      "  E:  coach\n",
      "\n",
      "Ground truth: option B\n"
     ]
    }
   ],
   "source": [
    "show_one(dataset[\"train\"][7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53fdef3-f11e-443e-bc22-01526f51481a",
   "metadata": {},
   "source": [
    "# Fine-tune the BERT model - with Trainer API\n",
    "Then we should download the pretrained model and fine-tune it on our commonsense QA dataset. Since all our task is about mutliple choice, we use the AutoModelForMultipleChoice class. Like with the tokenizer, the from_pretrained method will download and cache the model for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e263c16b-fe29-4e50-aefb-eafff06b4fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5502de-ba27-4e0d-bf5a-ab58b6cae3b2",
   "metadata": {},
   "source": [
    "### Evaluation function for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9ab03bd-052c-4e63-84d0-08b61c268927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# Load the accuracy metric\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da4f2e83-5831-4544-89b7-cc07259b226b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # Unpack predictions and labels\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # Get the index of the highest logit for each example\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Compute accuracy\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fe07a2-513c-461d-be22-c43cabae7b76",
   "metadata": {},
   "source": [
    "### Fine-tune using Hugging Face Trainer API\n",
    "Here we define TrainingArguments for the Trainer, which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional. Here we set the evaluation to be done at the end of each epoch, and adjust the learning rate, using the batch_size defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "910a2834-99ec-4157-a03d-fcf21036fe38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-csQA\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf4869e-2fd6-4306-adca-03856c703def",
   "metadata": {},
   "source": [
    "Then we just need to pass all of this along with our datasets to the Hugging Face Trainer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9270ec8-42e2-43c5-86c8-ef2540383839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769cb1f6-1a20-47b4-8bbd-d5b71666f054",
   "metadata": {},
   "source": [
    "Start the fine-tune process and retrain the model on our commonsenseQA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0681ae0-f5f3-4622-9aee-237a1ba3d9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='915' max='915' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [915/915 04:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.074509</td>\n",
       "      <td>0.578215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.073800</td>\n",
       "      <td>1.197831</td>\n",
       "      <td>0.587224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.073800</td>\n",
       "      <td>1.418299</td>\n",
       "      <td>0.582310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=915, training_loss=0.8009680576011783, metrics={'train_runtime': 269.3162, 'train_samples_per_second': 108.508, 'train_steps_per_second': 3.397, 'total_flos': 2979924348904950.0, 'train_loss': 0.8009680576011783, 'epoch': 3.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e5781b-a90d-4d9d-93c7-a546747409d2",
   "metadata": {},
   "source": [
    "# Fine-tune the BERT model - with self-defined training loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faea4b1f-e6b3-43fa-ad0c-e3895e2a433b",
   "metadata": {},
   "source": [
    "### Define the dataloaders\n",
    "We need to define the dataloaders that we will use to iterate over batches. Before that, we need to get a instance of the DataCollatorForMultipleChoice we defined earlier, which will be used to defined the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e541efd2-2bf5-47d6-8dff-7e0c7f2fca4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0678d2e-e299-4f2f-9721-fcc2ef3e7c06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    encoded_dataset[\"train\"], shuffle=True, batch_size=batch_size, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    encoded_dataset[\"validation\"], batch_size=batch_size, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca08af-f0c9-485f-80a8-14a64c751329",
   "metadata": {},
   "source": [
    "To quickly check there is no mistake in the data processing, we can inspect a batch like this.\n",
    "\n",
    "The shapes will probably be slightly different after each time running the code, since we set shuffle=True for the training dataloader and we are padding to the maximum length inside the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94e59191-9320-478f-bd4a-c4f278b51149",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([16, 5, 50]),\n",
       " 'token_type_ids': torch.Size([16, 5, 50]),\n",
       " 'attention_mask': torch.Size([16, 5, 50]),\n",
       " 'labels': torch.Size([16])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ab5cc1-9cf5-47fd-a094-5fdf4dd6f3a2",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8b3ae8a-6211-4515-b62f-9cce0759928a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57be284f-9073-4afa-b128-8915049c9f98",
   "metadata": {},
   "source": [
    "To make sure that everything will go smoothly during training, we pass a batch to this model for checking.\n",
    "As stated in the Hugging Face documentation, All Huggin Face Transformers models will return the loss when labels are provided, and we also get the logits (two for each input in our batch, so a tensor of size 8 x 5 in our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5dcfe79-7a1c-4fac-a67c-229e8d5d68ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5778, grad_fn=<NllLossBackward0>) torch.Size([16, 5])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**batch)\n",
    "print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0185b6ef-fd7a-454d-860e-c9e261539818",
   "metadata": {},
   "source": [
    "### Define the optimizer\n",
    "We will use the same defaults as the Hugging Face Trainer API, where the optimizer used by the Trainer is AdamW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e604eb6-2dea-473f-b532-fa77a7f9f03f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb6b3fe-673e-4e89-9040-8634ddb34758",
   "metadata": {},
   "source": [
    "### Define the learning rate scheduler\n",
    "The learning rate scheduler used by default is just a linear decay from the maximum value (5e-5) to 0. To properly define it, we need to know the number of training steps we will take, which is the number of epochs we want to run multiplied by the number of training batches (which is the length of our training dataloader). The Trainer uses three epochs by default, so we will follow that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3da9104b-a35a-4e7f-9953-3678fcd0467c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1827\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34a703d-eef3-4872-bf84-8d073b14320c",
   "metadata": {},
   "source": [
    "### Define the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34418aea-7792-4abe-81ac-8b424a2a6681",
   "metadata": {},
   "source": [
    "Enable distributed training on multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6c1b198-0f35-4b4b-afac-0a735ca4e22e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "# instantiates an Accelerator object that will look at the environment and initialize the proper distributed setup.\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# this will wrap those objects in the proper container to make sure our distributed training works as intended.\n",
    "train_dl, eval_dl, model, optimizer = accelerator.prepare(\n",
    "    train_dataloader, eval_dataloader, model, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74cbdb0-7ab4-4158-9f5d-014decc96308",
   "metadata": {},
   "source": [
    "**The training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "402d5bb5-2ed2-40de-9087-05c2827555ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c670e11f7ab244b08c85875259d6d80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1827 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# add a progress bar over our number of training steps\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dl:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0d8a23-4049-4caf-a977-cf57ee88c489",
   "metadata": {},
   "source": [
    "### Define the evaluation loop\n",
    "Metrics can actually accumulate batches for us as we go over the prediction loop with the method add_batch(). So, once we have accumulated all the batches, we can get the final result with metric.compute()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6bce9a74-d285-4c70-81c8-b90a85f3d56f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5798525798525799}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "model.eval()\n",
    "for batch in eval_dl:\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d335d807-1a7a-43a0-9636-b9e70123cafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "447c9f25-6c20-4da1-8db0-b0f8a0066971",
   "metadata": {},
   "source": [
    "### important! The code above is still using the single GPU!\n",
    "To utilize the multiple GPU, we need to rather putting them into a train.py script and run the command `accelerate config` and `accelerate launch train.py`, or using the `notebook_launcher` if we are using multiple GPU inside the notebook\n",
    "\n",
    "However, if we are doing it here, it always give the following error:\n",
    "ValueError: To launch a multi-GPU training from your notebook, the `Accelerator` should only be initialized inside your training function. Restart your notebook and make sure no cells initializes an `Accelerator`.\n",
    "\n",
    "**Important!!!**\n",
    "**Important!!!**\n",
    "**Important!!!**\n",
    "\n",
    "\n",
    "As it requires the `Accelerator` only show up in the training_function, and not in any other cells, even not allowed to exist in comments, so we move the version of self-defined training loops with multiple GPU into a separate notebook called `BERT_finetune_CSQA_notebook_launcher.ipynb`. Please refer to that notebook for our version of self-defined training loops with multiple GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0840c67-a6c3-4b7b-a3f4-cc72ab8160a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7c51d0-ddeb-4561-87b9-6ecb70a0a414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e7ef77-a4e2-4e7a-be37-e9764cf90825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbfaffb-8be4-4f90-bc22-8133c9554a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.4.0",
   "language": "python",
   "name": "pytorch-2.4.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
